# Hands-On Large Language Models

[home](../)

![Cover Image](hands-on-large-language-models.jpeg)

## Details

* **Title**: Hands-On Large Language Models
* **Subtitle**: Language Understanding and Generation
* **Authors**: Jay Alammar and Maarten Grootendorst
* **Publication Date**: 2024
* **Publisher**: O'Reilly
* **ISBN-13**: 978-1098150969
* **Pages**: 425
* **Amazon Rating**: 4.7 stars
* **Goodreads Rating**: 4.38 stars


**Links**: [Amazon](https://a.co/d/hXs5jDF) |
[Goodreads](https://www.goodreads.com/book/show/210408850-hands-on-large-language-models) |
[Publisher](https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/) |
[GitHub Project](https://github.com/HandsOnLLM/Hands-On-Large-Language-Models)

## Blurb

AI has acquired startling new language capabilities in just the past few years. Driven by rapid advances in deep learning, language AI systems are able to write and understand text better than ever before. This trend is enabling new features, products, and entire industries. Through this book's visually educational nature, readers will learn practical tools and concepts they need to use these capabilities today.

You'll understand how to use pretrained large language models for use cases like copywriting and summarization; create semantic search systems that go beyond keyword matching; and use existing libraries and pretrained models for text classification, search, and clusterings.

This book also helps you:

* Understand the architecture of Transformer language models that excel at text generation and representation
* Build advanced LLM pipelines to cluster text documents and explore the topics they cover
* Build semantic search engines that go beyond keyword search, using methods like dense retrieval and rerankers
* Explore how generative models can be used, from prompt engineering all the way to retrieval-augmented generation
* Gain a deeper understanding of how to train LLMs and optimize them for specific applications using generative model fine-tuning, contrastive fine-tuning, and in-context learning

## Contents

1. Introduction to Language Models
2. Tokens and Embeddings
3. Looking Inside Transformer LLMs
4. Text Classification
5. Text Clustering and Topic Modeling
6. Prompt Engineering
7. Advanced Text Generation Techniques and Tools
8. Semantic Search and Retrieval-Augmented Generation
9. Multimodal Large Language Models
10. Creating Text Embedding Models
11. Fine-tuning Representation Models for Classification
12. Fine-tuning Generation Models
